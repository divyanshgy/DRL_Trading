{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sXWgMmnXF-qx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from textblob import TextBlob"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#assuming df has column ticker and news"
      ],
      "metadata": {
        "id": "wfpkBcj4GWd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_polarity_subjectivity(text):\n",
        "    blob = TextBlob(text)\n",
        "    return blob.sentiment.polarity, blob.sentiment.subjectivity"
      ],
      "metadata": {
        "id": "kQgQdOZbGcJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[['polarity', 'subjectivity']]=df['news'].apply(lambda x: pd.Series(compute_polarity_subjectivity(x)))"
      ],
      "metadata": {
        "id": "myZQ_Uk3GmJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def assign_sentiment_label(polarity):\n",
        "    if polarity > 0:\n",
        "        return 1\n",
        "    elif polarity < 0:\n",
        "        return -1\n",
        "    else:\n",
        "        return 0"
      ],
      "metadata": {
        "id": "wTnQ8BywH8_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['sentiment_label'] = df['polarity'].apply(assign_sentiment_label)"
      ],
      "metadata": {
        "id": "KyLF3kBmH9yz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(7)"
      ],
      "metadata": {
        "id": "MMRagbVBIEnh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenizing and preparing data for BERT\n",
        "from transformers import BertTokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "train_texts = train_df['news'].tolist()\n",
        "train_labels = train_df['sentiment_label'].tolist()\n",
        "\n",
        "test_texts = test_df['news'].tolist()\n",
        "test_labels = test_df['sentiment_label'].tolist()\n",
        "\n",
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=128)\n",
        "test_encodings = tokenizer(test_texts, truncation=True, padding=True, max_length=128)"
      ],
      "metadata": {
        "id": "P0I4ff40IIgu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#PyTorch dataset to pass data to BERT\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class NewsDataset(Dataset):\n",
        "  def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "  def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "  def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = NewsDataset(train_encodings, train_labels)\n",
        "test_dataset = NewsDataset(test_encodings, test_labels)"
      ],
      "metadata": {
        "id": "ICnKZpBLS9-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fine-tuning\n",
        "from transformers import BertForSequenceClassification, Trainer, TrainingArguments\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # output directory\n",
        "    evaluation_strategy=\"epoch\",     # evaluate during training at each epoch\n",
        "    per_device_train_batch_size=16,  # batch size for training\n",
        "    per_device_eval_batch_size=16,   # batch size for evaluation\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    logging_dir='./logs',            # directory for storing logs\n",
        "    logging_steps=10,                # logs recorded every 10 steps\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "trainer.evaluate()"
      ],
      "metadata": {
        "id": "5MjSPZYyVYw3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}